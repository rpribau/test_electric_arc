{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libreta 3: Detección de Anomalías con LSTM Autoencoder + GMM\n",
    "\n",
    "**Objetivo:** Implementar un modelo avanzado que utiliza un LSTM Autoencoder para aprender representaciones de secuencias de tiempo (los \"ojos\") y un Modelo de Mezcla de Gaussianas (GMM) para clusterizar estas representaciones y entender los estados operativos normales del horno (el \"cerebro\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar y Preparar los Datos\n",
    "\n",
    "- Cargamos el archivo `all_heats_consolidated.csv`.\n",
    "- Seleccionamos un subconjunto de `HEATID`s para un desarrollo y entrenamiento más rápido. **Para el entrenamiento final, se debe usar el dataframe completo.**\n",
    "- Escalamos las características numéricas a un rango de `[0, 1]`.\n",
    "- Creamos las secuencias de datos (ventanas deslizantes) que servirán de entrada al Autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuraciones\n",
    "FILE_PATH = 'all_heats_consolidated.csv'\n",
    "TIME_STEPS = 15  # Usaremos secuencias de 15 minutos\n",
    "N_HEATIDS_TO_USE = None # Número de HEATIDs para usar en este ejemplo. Cambiar a un número mayor o None para usar todos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos consolidados...\n",
      "Datos cargados. Dimensiones: (7943618, 17)\n",
      "\n",
      "Se usarán 15 características para el modelo.\n",
      "Datos escalados.\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando datos consolidados...\")\n",
    "try:\n",
    "    df = pd.read_csv(FILE_PATH)\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    print(f\"Datos cargados. Dimensiones: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: El archivo {FILE_PATH} no fue encontrado. Asegúrate de ejecutar la libreta de preprocesamiento primero.\")\n",
    "    exit()\n",
    "\n",
    "# Seleccionar un subconjunto de HEATIDs para agilizar el desarrollo\n",
    "if N_HEATIDS_TO_USE is not None:\n",
    "    unique_heatids = df['HEATID'].unique()\n",
    "    selected_heatids = unique_heatids[:N_HEATIDS_TO_USE]\n",
    "    df = df[df['HEATID'].isin(selected_heatids)]\n",
    "    print(f\"Usando un subconjunto de {len(selected_heatids)} HEATIDs.\")\n",
    "\n",
    "# Identificar columnas de características (excluyendo Timestamp y HEATID)\n",
    "features = [col for col in df.columns if col not in ['Timestamp', 'HEATID']]\n",
    "print(f\"\\nSe usarán {len(features)} características para el modelo.\")\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = MinMaxScaler()\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "print(\"Datos escalados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando secuencias de 15 pasos de tiempo...\n",
      "Se crearon 7652040 secuencias.\n",
      "Dimensiones de las secuencias: (7652040, 15, 15)\n"
     ]
    }
   ],
   "source": [
    "# Función para crear secuencias agrupadas por HEATID\n",
    "def create_grouped_sequences(data, group_by_col, features, time_steps=10):\n",
    "    all_sequences = []\n",
    "    grouped = data.groupby(group_by_col)\n",
    "    for _, group in grouped:\n",
    "        ts_data = group[features].values\n",
    "        if len(ts_data) > time_steps:\n",
    "            for i in range(len(ts_data) - time_steps + 1):\n",
    "                all_sequences.append(ts_data[i:(i + time_steps)])\n",
    "    return np.array(all_sequences)\n",
    "\n",
    "print(f\"Creando secuencias de {TIME_STEPS} pasos de tiempo...\")\n",
    "sequences = create_grouped_sequences(df, 'HEATID', features, TIME_STEPS)\n",
    "print(f\"Se crearon {sequences.shape[0]} secuencias.\")\n",
    "print(f\"Dimensiones de las secuencias: {sequences.shape}\") # (n_secuencias, n_pasos_tiempo, n_características)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Construir el Modelo LSTM Autoencoder\n",
    "\n",
    "El Autoencoder consta de dos partes:\n",
    "1.  **Encoder:** Un LSTM que lee la secuencia de entrada y la comprime en un vector de estado de baja dimensión (la \"memoria\" o \"representación latente\").\n",
    "2.  **Decoder:** Otro LSTM que toma el vector de estado y intenta reconstruir la secuencia de entrada original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,935</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m73,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m24,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m)         │         \u001b[38;5;34m1,935\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,799</span> (979.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m250,799\u001b[0m (979.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,799</span> (979.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m250,799\u001b[0m (979.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_features = sequences.shape[2]\n",
    "latent_dim = 32 # Dimensión del espacio latente (la \"memoria\"), esto lo hacemos para capturar la información más relevante de la secuencia de entrada\n",
    "\n",
    "# --- Encoder ---\n",
    "input_seq = Input(shape=(TIME_STEPS, n_features))\n",
    "encoder = LSTM(128, activation='relu', return_sequences=True)(input_seq)\n",
    "encoder = LSTM(64, activation='relu', return_sequences=False)(encoder)\n",
    "latent_vector = Dense(latent_dim, activation='relu')(encoder) # El \"vector de memoria\"\n",
    "\n",
    "# --- Decoder ---\n",
    "# Repetimos el vector latente para cada paso de tiempo de la salida\n",
    "decoder_input = RepeatVector(TIME_STEPS)(latent_vector)\n",
    "decoder = LSTM(64, activation='relu', return_sequences=True)(decoder_input)\n",
    "decoder = LSTM(128, activation='relu', return_sequences=True)(decoder)\n",
    "output_seq = TimeDistributed(Dense(n_features))(decoder)\n",
    "\n",
    "# --- Autoencoder Model ---\n",
    "autoencoder = Model(inputs=input_seq, outputs=output_seq)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Entrenar el Autoencoder\n",
    "\n",
    "Entrenamos el modelo para que aprenda a reconstruir secuencias \"normales\". El objetivo es minimizar el error de reconstrucción (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el LSTM Autoencoder...\n",
      "Epoch 1/20\n",
      "\u001b[1m107607/107607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3010s\u001b[0m 28ms/step - loss: 2.6010e-04 - val_loss: 1.1879e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m107607/107607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3296s\u001b[0m 31ms/step - loss: 7.2566e-05 - val_loss: 7.4370e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m107607/107607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3544s\u001b[0m 33ms/step - loss: 5.2811e-05 - val_loss: 5.3606e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m107607/107607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3823s\u001b[0m 36ms/step - loss: 4.3574e-05 - val_loss: 4.9555e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m107607/107607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4252s\u001b[0m 40ms/step - loss: 3.7833e-05 - val_loss: 5.0806e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m107607/107607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5544s\u001b[0m 52ms/step - loss: 3.4571e-05 - val_loss: 3.7822e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m107607/107607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6942s\u001b[0m 65ms/step - loss: 3.1779e-05 - val_loss: 3.7109e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m107607/107607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7788s\u001b[0m 72ms/step - loss: 2.9401e-05 - val_loss: 3.4830e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m107607/107607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8768s\u001b[0m 81ms/step - loss: 2.8480e-05 - val_loss: 3.5440e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m 76870/107607\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m45:11\u001b[0m 88ms/step - loss: 2.6892e-05"
     ]
    }
   ],
   "source": [
    "print(\"Entrenando el LSTM Autoencoder...\")\n",
    "history = autoencoder.fit(\n",
    "    sequences, sequences, # La entrada y la salida son las mismas\n",
    "    epochs=20, # Aumentar para un mejor rendimiento en el dataset completo\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
    "    ]\n",
    ")\n",
    "print(\"Entrenamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Extraer Representaciones Latentes (las \"Memorias\")\n",
    "\n",
    "Ahora que el autoencoder está entrenado, creamos un modelo separado solo con la parte del **Encoder**. Usaremos este modelo para convertir todas nuestras secuencias normales en sus correspondientes \"vectores de memoria\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=input_seq, outputs=latent_vector)\n",
    "\n",
    "print(\"Extrayendo representaciones latentes de las secuencias...\")\n",
    "latent_representations = encoder_model.predict(sequences)\n",
    "print(f\"Dimensiones de las representaciones latentes: {latent_representations.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Entrenar el Modelo de Mezcla de Gaussianas (GMM)\n",
    "\n",
    "Usamos el GMM para encontrar clusters en el espacio de las representaciones latentes. Cada cluster representará un \"estado operativo\" normal del horno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS = 5 # Hipótesis: hay 5 estados operativos principales. Se puede ajustar.\n",
    "\n",
    "print(f\"Entrenando el GMM con {N_CLUSTERS} clusters...\")\n",
    "gmm = GaussianMixture(n_components=N_CLUSTERS, random_state=42)\n",
    "gmm.fit(latent_representations)\n",
    "print(\"Entrenamiento del GMM completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6: Definir Lógica de Detección de Anomalías\n",
    "\n",
    "Ahora tenemos dos formas de detectar anomalías:\n",
    "1.  **Error de Reconstrucción (Anomalía de Forma):** Si el autoencoder no puede reconstruir bien una secuencia, significa que la forma de la secuencia es anómala. Usaremos un umbral estadístico sobre el error (MSE).\n",
    "2.  **Probabilidad del GMM (Anomalía de Estado):** Si una secuencia se reconstruye bien pero su \"memoria\" no encaja en ninguno de los clusters normales, es una anomalía de estado. Usaremos un umbral sobre el score de probabilidad del GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calcular errores de reconstrucción\n",
    "print(\"Calculando errores de reconstrucción...\")\n",
    "reconstructed_seqs = autoencoder.predict(sequences)\n",
    "reconstruction_errors = np.mean(np.square(sequences - reconstructed_seqs), axis=(1, 2))\n",
    "\n",
    "# Definir umbral para el error de reconstrucción\n",
    "reconstruction_threshold = np.mean(reconstruction_errors) + 3 * np.std(reconstruction_errors)\n",
    "print(f\"Umbral para error de reconstrucción (MSE): {reconstruction_threshold:.4f}\")\n",
    "\n",
    "# 2. Calcular scores de probabilidad del GMM\n",
    "print(\"Calculando scores de probabilidad del GMM...\")\n",
    "gmm_scores = gmm.score_samples(latent_representations)\n",
    "\n",
    "# Definir umbral para el score del GMM (usando un percentil)\n",
    "gmm_threshold = np.percentile(gmm_scores, 5) # Consideramos anómalo el 5% de los estados menos probables\n",
    "print(f\"Umbral para score del GMM (log-probabilidad): {gmm_threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 7: Aplicar y Visualizar Resultados en un HEATID de Ejemplo\n",
    "\n",
    "Tomamos un `HEATID` del conjunto de prueba y aplicamos nuestra lógica de detección para ver los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomar el primer HEATID como ejemplo\n",
    "example_heatid = df['HEATID'].unique()[0]\n",
    "df_example = df[df['HEATID'] == example_heatid]\n",
    "\n",
    "# Crear secuencias para este HEATID\n",
    "example_seqs = create_grouped_sequences(df_example, 'HEATID', features, TIME_STEPS)\n",
    "\n",
    "# Obtener predicciones y scores para el ejemplo\n",
    "example_reconstructed = autoencoder.predict(example_seqs)\n",
    "example_errors = np.mean(np.square(example_seqs - example_reconstructed), axis=(1, 2))\n",
    "example_latent = encoder_model.predict(example_seqs)\n",
    "example_gmm_scores = gmm.score_samples(example_latent)\n",
    "\n",
    "# Crear un dataframe con los resultados\n",
    "df_plot = pd.DataFrame(index=df_example.index[TIME_STEPS-1:])\n",
    "df_plot['Reconstruction_Error'] = example_errors\n",
    "df_plot['GMM_Score'] = example_gmm_scores\n",
    "df_plot['Reconstruction_Anomaly'] = example_errors > reconstruction_threshold\n",
    "df_plot['State_Anomaly'] = example_gmm_scores < gmm_threshold\n",
    "df_plot['TEMP'] = df_example['TEMP'][TIME_STEPS-1:]\n",
    "\n",
    "print(f\"Resultados para HEATID: {example_heatid}\")\n",
    "print(df_plot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar los resultados\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(18, 10), sharex=True)\n",
    "\n",
    "# Gráfico del Error de Reconstrucción\n",
    "ax1.plot(df_plot.index, df_plot['Reconstruction_Error'], label='Error de Reconstrucción (MSE)')\n",
    "ax1.axhline(reconstruction_threshold, color='r', linestyle='--', label='Umbral')\n",
    "ax1.scatter(df_plot.index[df_plot['Reconstruction_Anomaly']], df_plot['Reconstruction_Error'][df_plot['Reconstruction_Anomaly']], color='red', label='Anomalía de Forma')\n",
    "ax1.set_title(f'Anomalías de Reconstrucción para {example_heatid}')\n",
    "ax1.set_ylabel('MSE Error')\n",
    "ax1.legend()\n",
    "\n",
    "# Gráfico del Score del GMM\n",
    "ax2.plot(df_plot.index, df_plot['GMM_Score'], label='Score de Probabilidad del GMM')\n",
    "ax2.axhline(gmm_threshold, color='r', linestyle='--', label='Umbral')\n",
    "ax2.scatter(df_plot.index[df_plot['State_Anomaly']], df_plot['GMM_Score'][df_plot['State_Anomaly']], color='red', label='Anomalía de Estado')\n",
    "ax2.set_title(f'Anomalías de Estado Operativo para {example_heatid}')\n",
    "ax2.set_ylabel('Log-Probabilidad')\n",
    "ax2.set_xlabel('Timestamp')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
